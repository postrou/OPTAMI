{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ccf398-83a3-4891-8e68-9727acd71456",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb046398-bb9e-4553-b4c7-400a34ca0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from mnist import MNIST\n",
    "\n",
    "from OPTAMI import PrimalDualAccelerated\n",
    "from run_pd_experiment import run_experiment, cartesian_product, calculate_lipschitz_constant, calculate_M_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b0927c-33a7-4058-b554-f402493fad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 784\n",
    "m = int(np.sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0ea84-22bb-44b8-ab1b-c54e422a1acb",
   "metadata": {},
   "source": [
    "# Primal-Dual Tensor Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7311a2-ebb1-4400-933f-0a9e604d84c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6669, dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_matrix = calculate_M_matrix(m)\n",
    "M_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4485d6-d74a-44fe-991b-88e8ba06c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = 1e-3\n",
    "# gamma = 0.1\n",
    "eps = 0.02\n",
    "gamma = eps / 3 / np.log(n)\n",
    "image_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e012d0b5-a6f8-4fe5-9a51-3a86dedbfd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building matrix A: 100%|█████████████████████| 784/784 [00:02<00:00, 383.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.6843e+16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_p = calculate_lipschitz_constant(n, gamma, p_order=3)\n",
    "M_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18be7e91-82e4-40d7-bdde-494bc0ec4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ot_softmax():\n",
    "    # log_B = M_over_gamma + torch.outer(psi, torch.ones(n)) + torch.outer(eta, torch.ones(n))\n",
    "    # max_log_B = log_B.max()\n",
    "    # log_B_stable = log_B - max_log_B\n",
    "    # B_stable = torch.exp(log_b_stable)\n",
    "    \n",
    "    # return gamma * (torch.log(B_stable.sum()) + max_log_B - lamb @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d61cc7c-e8b8-4684-912f-ce2fa319331c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, criterion=6.657424764967158, phi=6.664091431633825, f=-0.006666666666666445\n",
      "lambda=tensor([-1.5917e-07, -1.5917e-07, -1.5917e-07,  ..., -1.5917e-07,\n",
      "        -1.5917e-07, -1.5917e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #2, criterion=6.657396964604002, phi=6.664063631270669, f=-0.006666666666666425\n",
      "lambda=tensor([-1.7310e-07, -1.7310e-07, -1.7310e-07,  ..., -1.7310e-07,\n",
      "        -1.7310e-07, -1.7310e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #3, criterion=6.657339390284144, phi=6.66400605695081, f=-0.006666666666666365\n",
      "lambda=tensor([-2.0195e-07, -2.0195e-07, -2.0195e-07,  ..., -2.0195e-07,\n",
      "        -2.0195e-07, -2.0195e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #4, criterion=6.657272179831643, phi=6.663938846498309, f=-0.006666666666666276\n",
      "lambda=tensor([-2.3564e-07, -2.3564e-07, -2.3564e-07,  ..., -2.3564e-07,\n",
      "        -2.3564e-07, -2.3564e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #5, criterion=6.657200387774698, phi=6.663867054272495, f=-0.0066666664977964194\n",
      "lambda=tensor([-2.7162e-07, -2.7162e-07, -2.7162e-07,  ..., -2.7162e-07,\n",
      "        -2.7162e-07, -2.7162e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #6, criterion=6.657125856996271, phi=6.663792523581499, f=-0.0066666665852280795\n",
      "lambda=tensor([-3.0897e-07, -3.0897e-07, -3.0897e-07,  ..., -3.0897e-07,\n",
      "        -3.0897e-07, -3.0897e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #7, criterion=6.6570494395276745, phi=6.663716106150382, f=-0.0066666666227076935\n",
      "lambda=tensor([-3.4727e-07, -3.4727e-07, -3.4727e-07,  ..., -3.4727e-07,\n",
      "        -3.4727e-07, -3.4727e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #8, criterion=6.6569715953532675, phi=6.663638261994166, f=-0.0066666666408982354\n",
      "lambda=tensor([-3.8628e-07, -3.8628e-07, -3.8628e-07,  ..., -3.8628e-07,\n",
      "        -3.8628e-07, -3.8628e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #9, criterion=6.656892601846668, phi=6.663559268497247, f=-0.00666666665057902\n",
      "lambda=tensor([-4.2587e-07, -4.2587e-07, -4.2587e-07,  ..., -4.2587e-07,\n",
      "        -4.2587e-07, -4.2587e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #10, criterion=6.656812640603919, phi=6.66347930726003, f=-0.006666666656110967\n",
      "lambda=tensor([-4.6594e-07, -4.6594e-07, -4.6594e-07,  ..., -4.6594e-07,\n",
      "        -4.6594e-07, -4.6594e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #11, criterion=6.656731838453713, phi=6.66339850511317, f=-0.006666666659456337\n",
      "lambda=tensor([-5.0644e-07, -5.0644e-07, -5.0644e-07,  ..., -5.0644e-07,\n",
      "        -5.0644e-07, -5.0644e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #12, criterion=6.656650288231439, phi=6.663316954893014, f=-0.006666666661574993\n",
      "lambda=tensor([-5.4731e-07, -5.4731e-07, -5.4731e-07,  ..., -5.4731e-07,\n",
      "        -5.4731e-07, -5.4731e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #13, criterion=6.656568060998183, phi=6.663234727661153, f=-0.006666666662969244\n",
      "lambda=tensor([-5.8852e-07, -5.8852e-07, -5.8852e-07,  ..., -5.8852e-07,\n",
      "        -5.8852e-07, -5.8852e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #14, criterion=6.656485212625887, phi=6.663151879289804, f=-0.006666666663916954\n",
      "lambda=tensor([-6.3004e-07, -6.3004e-07, -6.3004e-07,  ..., -6.3004e-07,\n",
      "        -6.3004e-07, -6.3004e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #15, criterion=6.656401788447714, phi=6.663068455112294, f=-0.006666666664579235\n",
      "lambda=tensor([-6.7185e-07, -6.7185e-07, -6.7185e-07,  ..., -6.7185e-07,\n",
      "        -6.7185e-07, -6.7185e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #16, criterion=6.65631782591863, phi=6.662984492583683, f=-0.006666666665053264\n",
      "lambda=tensor([-7.1393e-07, -7.1393e-07, -7.1393e-07,  ..., -7.1393e-07,\n",
      "        -7.1393e-07, -7.1393e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #17, criterion=6.656233356710693, phi=6.662900023376093, f=-0.006666666665399718\n",
      "lambda=tensor([-7.5626e-07, -7.5626e-07, -7.5626e-07,  ..., -7.5626e-07,\n",
      "        -7.5626e-07, -7.5626e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #18, criterion=6.656148407891212, phi=6.66281507455687, f=-0.00666666666565763\n",
      "lambda=tensor([-7.9883e-07, -7.9883e-07, -7.9883e-07,  ..., -7.9883e-07,\n",
      "        -7.9883e-07, -7.9883e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #19, criterion=6.656063003024736, phi=6.662729669690588, f=-0.006666666665852788\n",
      "lambda=tensor([-8.4164e-07, -8.4164e-07, -8.4164e-07,  ..., -8.4164e-07,\n",
      "        -8.4164e-07, -8.4164e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #20, criterion=6.655977162716865, phi=6.662643829382867, f=-0.006666666666002617\n",
      "lambda=tensor([-8.8466e-07, -8.8466e-07, -8.8466e-07,  ..., -8.8466e-07,\n",
      "        -8.8466e-07, -8.8466e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #21, criterion=6.6558909053271895, phi=6.662557571993308, f=-0.006666666666119159\n",
      "lambda=tensor([-9.2788e-07, -9.2788e-07, -9.2788e-07,  ..., -9.2788e-07,\n",
      "        -9.2788e-07, -9.2788e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #22, criterion=6.655804247424348, phi=6.66247091409056, f=-0.006666666666210873\n",
      "lambda=tensor([-9.7131e-07, -9.7131e-07, -9.7131e-07,  ..., -9.7131e-07,\n",
      "        -9.7131e-07, -9.7131e-07], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #23, criterion=6.655717203428941, phi=6.662383870095225, f=-0.00666666666628381\n",
      "lambda=tensor([-1.0149e-06, -1.0149e-06, -1.0149e-06,  ..., -1.0149e-06,\n",
      "        -1.0149e-06, -1.0149e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #24, criterion=6.655629786974416, phi=6.662296453640758, f=-0.006666666666342373\n",
      "lambda=tensor([-1.0587e-06, -1.0587e-06, -1.0587e-06,  ..., -1.0587e-06,\n",
      "        -1.0587e-06, -1.0587e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #25, criterion=6.655542010180677, phi=6.662208676847067, f=-0.006666666666389798\n",
      "lambda=tensor([-1.1027e-06, -1.1027e-06, -1.1027e-06,  ..., -1.1027e-06,\n",
      "        -1.1027e-06, -1.1027e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #26, criterion=6.655453884379907, phi=6.6621205510463355, f=-0.006666666666428507\n",
      "lambda=tensor([-1.1469e-06, -1.1469e-06, -1.1469e-06,  ..., -1.1469e-06,\n",
      "        -1.1469e-06, -1.1469e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #27, criterion=6.655365419721364, phi=6.662032086387825, f=-0.006666666666460325\n",
      "lambda=tensor([-1.1912e-06, -1.1912e-06, -1.1912e-06,  ..., -1.1912e-06,\n",
      "        -1.1912e-06, -1.1912e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #28, criterion=6.655276625907443, phi=6.6619432925739295, f=-0.00666666666648665\n",
      "lambda=tensor([-1.2357e-06, -1.2357e-06, -1.2357e-06,  ..., -1.2357e-06,\n",
      "        -1.2357e-06, -1.2357e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #29, criterion=6.65518751176403, phi=6.661854178430539, f=-0.006666666666508551\n",
      "lambda=tensor([-1.2804e-06, -1.2804e-06, -1.2804e-06,  ..., -1.2804e-06,\n",
      "        -1.2804e-06, -1.2804e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #30, criterion=6.655098085571129, phi=6.661764752237655, f=-0.00666666666652687\n",
      "lambda=tensor([-1.3252e-06, -1.3252e-06, -1.3252e-06,  ..., -1.3252e-06,\n",
      "        -1.3252e-06, -1.3252e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #31, criterion=6.655008355027713, phi=6.661675021694255, f=-0.0066666666665422545\n",
      "lambda=tensor([-1.3702e-06, -1.3702e-06, -1.3702e-06,  ..., -1.3702e-06,\n",
      "        -1.3702e-06, -1.3702e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #32, criterion=6.6549183274282475, phi=6.661584994094802, f=-0.006666666666555235\n",
      "lambda=tensor([-1.4153e-06, -1.4153e-06, -1.4153e-06,  ..., -1.4153e-06,\n",
      "        -1.4153e-06, -1.4153e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #33, criterion=6.654828009487063, phi=6.661494676153629, f=-0.00666666666656622\n",
      "lambda=tensor([-1.4606e-06, -1.4606e-06, -1.4606e-06,  ..., -1.4606e-06,\n",
      "        -1.4606e-06, -1.4606e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #34, criterion=6.654737407933247, phi=6.661404074599822, f=-0.0066666666665755395\n",
      "lambda=tensor([-1.5060e-06, -1.5060e-06, -1.5060e-06,  ..., -1.5060e-06,\n",
      "        -1.5060e-06, -1.5060e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #35, criterion=6.654646528481985, phi=6.661313195148568, f=-0.006666666666583468\n",
      "lambda=tensor([-1.5515e-06, -1.5515e-06, -1.5515e-06,  ..., -1.5515e-06,\n",
      "        -1.5515e-06, -1.5515e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #36, criterion=6.6545553769839625, phi=6.661222043650553, f=-0.006666666666590219\n",
      "lambda=tensor([-1.5972e-06, -1.5972e-06, -1.5972e-06,  ..., -1.5972e-06,\n",
      "        -1.5972e-06, -1.5972e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #37, criterion=6.654463958869677, phi=6.6611306255362726, f=-0.006666666666595975\n",
      "lambda=tensor([-1.6430e-06, -1.6430e-06, -1.6430e-06,  ..., -1.6430e-06,\n",
      "        -1.6430e-06, -1.6430e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #38, criterion=6.654372279512157, phi=6.661038946178758, f=-0.006666666666600887\n",
      "lambda=tensor([-1.6890e-06, -1.6890e-06, -1.6890e-06,  ..., -1.6890e-06,\n",
      "        -1.6890e-06, -1.6890e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #39, criterion=6.654280343566454, phi=6.660947010233059, f=-0.006666666666605071\n",
      "lambda=tensor([-1.7350e-06, -1.7350e-06, -1.7350e-06,  ..., -1.7350e-06,\n",
      "        -1.7350e-06, -1.7350e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #40, criterion=6.654188155784876, phi=6.660854822451484, f=-0.006666666666608632\n",
      "lambda=tensor([-1.7812e-06, -1.7812e-06, -1.7812e-06,  ..., -1.7812e-06,\n",
      "        -1.7812e-06, -1.7812e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #41, criterion=6.654095720628951, phi=6.660762387295563, f=-0.006666666666611651\n",
      "lambda=tensor([-1.8276e-06, -1.8276e-06, -1.8276e-06,  ..., -1.8276e-06,\n",
      "        -1.8276e-06, -1.8276e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #42, criterion=6.654003042436185, phi=6.660669709102799, f=-0.006666666666614201\n",
      "lambda=tensor([-1.8740e-06, -1.8740e-06, -1.8740e-06,  ..., -1.8740e-06,\n",
      "        -1.8740e-06, -1.8740e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #43, criterion=6.653910125387568, phi=6.660576792054184, f=-0.0066666666666163445\n",
      "lambda=tensor([-1.9206e-06, -1.9206e-06, -1.9206e-06,  ..., -1.9206e-06,\n",
      "        -1.9206e-06, -1.9206e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #44, criterion=6.653816973287212, phi=6.66048363995383, f=-0.006666666666618127\n",
      "lambda=tensor([-1.9673e-06, -1.9673e-06, -1.9673e-06,  ..., -1.9673e-06,\n",
      "        -1.9673e-06, -1.9673e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #45, criterion=6.653723589730404, phi=6.660390256397024, f=-0.006666666666619596\n",
      "lambda=tensor([-2.0141e-06, -2.0141e-06, -2.0141e-06,  ..., -2.0141e-06,\n",
      "        -2.0141e-06, -2.0141e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #46, criterion=6.653629978413123, phi=6.660296645079744, f=-0.0066666666666207845\n",
      "lambda=tensor([-2.0610e-06, -2.0610e-06, -2.0610e-06,  ..., -2.0610e-06,\n",
      "        -2.0610e-06, -2.0610e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #47, criterion=6.653536143049341, phi=6.660202809715963, f=-0.006666666666621728\n",
      "lambda=tensor([-2.1080e-06, -2.1080e-06, -2.1080e-06,  ..., -2.1080e-06,\n",
      "        -2.1080e-06, -2.1080e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #48, criterion=6.6534420866351205, phi=6.660108753301743, f=-0.006666666666622453\n",
      "lambda=tensor([-2.1551e-06, -2.1551e-06, -2.1551e-06,  ..., -2.1551e-06,\n",
      "        -2.1551e-06, -2.1551e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #49, criterion=6.653347812494988, phi=6.660014479161611, f=-0.006666666666622978\n",
      "lambda=tensor([-2.2024e-06, -2.2024e-06, -2.2024e-06,  ..., -2.2024e-06,\n",
      "        -2.2024e-06, -2.2024e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #50, criterion=6.65325332383972, phi=6.659919990506343, f=-0.00666666666662333\n",
      "lambda=tensor([-2.2497e-06, -2.2497e-06, -2.2497e-06,  ..., -2.2497e-06,\n",
      "        -2.2497e-06, -2.2497e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #51, criterion=6.653158623643515, phi=6.659825290310138, f=-0.006666666666623518\n",
      "lambda=tensor([-2.2972e-06, -2.2972e-06, -2.2972e-06,  ..., -2.2972e-06,\n",
      "        -2.2972e-06, -2.2972e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #52, criterion=6.653063714574923, phi=6.6597303812415465, f=-0.006666666666623563\n",
      "lambda=tensor([-2.3448e-06, -2.3448e-06, -2.3448e-06,  ..., -2.3448e-06,\n",
      "        -2.3448e-06, -2.3448e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #53, criterion=6.652968599536299, phi=6.659635266202923, f=-0.006666666666623475\n",
      "lambda=tensor([-2.3924e-06, -2.3924e-06, -2.3924e-06,  ..., -2.3924e-06,\n",
      "        -2.3924e-06, -2.3924e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #54, criterion=6.6528732813759675, phi=6.659539948042591, f=-0.006666666666623269\n",
      "lambda=tensor([-2.4402e-06, -2.4402e-06, -2.4402e-06,  ..., -2.4402e-06,\n",
      "        -2.4402e-06, -2.4402e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #55, criterion=6.652777762623188, phi=6.659444429289811, f=-0.006666666666622953\n",
      "lambda=tensor([-2.4881e-06, -2.4881e-06, -2.4881e-06,  ..., -2.4881e-06,\n",
      "        -2.4881e-06, -2.4881e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #56, criterion=6.652682045505991, phi=6.659348712172614, f=-0.006666666666622536\n",
      "lambda=tensor([-2.5361e-06, -2.5361e-06, -2.5361e-06,  ..., -2.5361e-06,\n",
      "        -2.5361e-06, -2.5361e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #57, criterion=6.652586132960112, phi=6.659252799626734, f=-0.006666666666622024\n",
      "lambda=tensor([-2.5841e-06, -2.5841e-06, -2.5841e-06,  ..., -2.5841e-06,\n",
      "        -2.5841e-06, -2.5841e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #58, criterion=6.652490026924041, phi=6.6591566935906625, f=-0.006666666666621426\n",
      "lambda=tensor([-2.6323e-06, -2.6323e-06, -2.6323e-06,  ..., -2.6323e-06,\n",
      "        -2.6323e-06, -2.6323e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #59, criterion=6.652393729723633, phi=6.659060396390253, f=-0.006666666666620746\n",
      "lambda=tensor([-2.6805e-06, -2.6805e-06, -2.6805e-06,  ..., -2.6805e-06,\n",
      "        -2.6805e-06, -2.6805e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #60, criterion=6.652297244005681, phi=6.658963910672301, f=-0.006666666666619994\n",
      "lambda=tensor([-2.7289e-06, -2.7289e-06, -2.7289e-06,  ..., -2.7289e-06,\n",
      "        -2.7289e-06, -2.7289e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #61, criterion=6.652200571516794, phi=6.658867238183412, f=-0.0066666666666191695\n",
      "lambda=tensor([-2.7773e-06, -2.7773e-06, -2.7773e-06,  ..., -2.7773e-06,\n",
      "        -2.7773e-06, -2.7773e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #62, criterion=6.652103714407917, phi=6.658770381074535, f=-0.006666666666618279\n",
      "lambda=tensor([-2.8259e-06, -2.8259e-06, -2.8259e-06,  ..., -2.8259e-06,\n",
      "        -2.8259e-06, -2.8259e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #63, criterion=6.652006675093472, phi=6.658673341760089, f=-0.006666666666617324\n",
      "lambda=tensor([-2.8745e-06, -2.8745e-06, -2.8745e-06,  ..., -2.8745e-06,\n",
      "        -2.8745e-06, -2.8745e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #64, criterion=6.651909455030588, phi=6.658576121697204, f=-0.006666666666616309\n",
      "lambda=tensor([-2.9232e-06, -2.9232e-06, -2.9232e-06,  ..., -2.9232e-06,\n",
      "        -2.9232e-06, -2.9232e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #65, criterion=6.65181205619831, phi=6.658478722864925, f=-0.006666666666615237\n",
      "lambda=tensor([-2.9721e-06, -2.9721e-06, -2.9721e-06,  ..., -2.9721e-06,\n",
      "        -2.9721e-06, -2.9721e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #66, criterion=6.6517144809987965, phi=6.658381147665411, f=-0.006666666666614112\n",
      "lambda=tensor([-3.0210e-06, -3.0210e-06, -3.0210e-06,  ..., -3.0210e-06,\n",
      "        -3.0210e-06, -3.0210e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #67, criterion=6.651616730626005, phi=6.658283397292617, f=-0.0066666666666129375\n",
      "lambda=tensor([-3.0699e-06, -3.0699e-06, -3.0699e-06,  ..., -3.0699e-06,\n",
      "        -3.0699e-06, -3.0699e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #68, criterion=6.65151880756257, phi=6.658185474229182, f=-0.006666666666611714\n",
      "lambda=tensor([-3.1190e-06, -3.1190e-06, -3.1190e-06,  ..., -3.1190e-06,\n",
      "        -3.1190e-06, -3.1190e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #69, criterion=6.6514207125620555, phi=6.658087379228666, f=-0.006666666666610443\n",
      "lambda=tensor([-3.1682e-06, -3.1682e-06, -3.1682e-06,  ..., -3.1682e-06,\n",
      "        -3.1682e-06, -3.1682e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #70, criterion=6.651322448619163, phi=6.657989115285772, f=-0.006666666666609126\n",
      "lambda=tensor([-3.2174e-06, -3.2174e-06, -3.2174e-06,  ..., -3.2174e-06,\n",
      "        -3.2174e-06, -3.2174e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #71, criterion=6.651224016251589, phi=6.657890682918198, f=-0.006666666666607764\n",
      "lambda=tensor([-3.2668e-06, -3.2668e-06, -3.2668e-06,  ..., -3.2668e-06,\n",
      "        -3.2668e-06, -3.2668e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #72, criterion=6.651125417875886, phi=6.657792084542493, f=-0.006666666666606361\n",
      "lambda=tensor([-3.3162e-06, -3.3162e-06, -3.3162e-06,  ..., -3.3162e-06,\n",
      "        -3.3162e-06, -3.3162e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8930e-64,  ..., 2.8930e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #73, criterion=6.651026654171406, phi=6.6576933208380105, f=-0.0066666666666049135\n",
      "lambda=tensor([-3.3657e-06, -3.3657e-06, -3.3657e-06,  ..., -3.3657e-06,\n",
      "        -3.3657e-06, -3.3657e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #74, criterion=6.650927727392243, phi=6.6575943940588465, f=-0.006666666666603426\n",
      "lambda=tensor([-3.4153e-06, -3.4153e-06, -3.4153e-06,  ..., -3.4153e-06,\n",
      "        -3.4153e-06, -3.4153e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #75, criterion=6.65082863865083, phi=6.657495305317432, f=-0.0066666666666018995\n",
      "lambda=tensor([-3.4649e-06, -3.4649e-06, -3.4649e-06,  ..., -3.4649e-06,\n",
      "        -3.4649e-06, -3.4649e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #76, criterion=6.650729390076001, phi=6.657396056742601, f=-0.006666666666600335\n",
      "lambda=tensor([-3.5147e-06, -3.5147e-06, -3.5147e-06,  ..., -3.5147e-06,\n",
      "        -3.5147e-06, -3.5147e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #77, criterion=6.650629982060378, phi=6.657296648726977, f=-0.006666666666598733\n",
      "lambda=tensor([-3.5645e-06, -3.5645e-06, -3.5645e-06,  ..., -3.5645e-06,\n",
      "        -3.5645e-06, -3.5645e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #78, criterion=6.650530417020102, phi=6.6571970836866985, f=-0.006666666666597094\n",
      "lambda=tensor([-3.6144e-06, -3.6144e-06, -3.6144e-06,  ..., -3.6144e-06,\n",
      "        -3.6144e-06, -3.6144e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #79, criterion=6.650430695564576, phi=6.6570973622311715, f=-0.00666666666659542\n",
      "lambda=tensor([-3.6643e-06, -3.6643e-06, -3.6643e-06,  ..., -3.6643e-06,\n",
      "        -3.6643e-06, -3.6643e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #80, criterion=6.6503308195820665, phi=6.6569974862486605, f=-0.006666666666593706\n",
      "lambda=tensor([-3.7144e-06, -3.7144e-06, -3.7144e-06,  ..., -3.7144e-06,\n",
      "        -3.7144e-06, -3.7144e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #81, criterion=6.650230789926234, phi=6.6568974565928265, f=-0.00666666666659196\n",
      "lambda=tensor([-3.7645e-06, -3.7645e-06, -3.7645e-06,  ..., -3.7645e-06,\n",
      "        -3.7645e-06, -3.7645e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #82, criterion=6.650130608490898, phi=6.656797275157489, f=-0.006666666666590183\n",
      "lambda=tensor([-3.8147e-06, -3.8147e-06, -3.8147e-06,  ..., -3.8147e-06,\n",
      "        -3.8147e-06, -3.8147e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #83, criterion=6.650030275883396, phi=6.656696942549985, f=-0.006666666666588367\n",
      "lambda=tensor([-3.8650e-06, -3.8650e-06, -3.8650e-06,  ..., -3.8650e-06,\n",
      "        -3.8650e-06, -3.8650e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #84, criterion=6.649929793839927, phi=6.656596460506514, f=-0.006666666666586518\n",
      "lambda=tensor([-3.9154e-06, -3.9154e-06, -3.9154e-06,  ..., -3.9154e-06,\n",
      "        -3.9154e-06, -3.9154e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #85, criterion=6.649829163401979, phi=6.656495830068563, f=-0.006666666666584636\n",
      "lambda=tensor([-3.9658e-06, -3.9658e-06, -3.9658e-06,  ..., -3.9658e-06,\n",
      "        -3.9658e-06, -3.9658e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #86, criterion=6.649728385701152, phi=6.656395052367735, f=-0.00666666666658272\n",
      "lambda=tensor([-4.0163e-06, -4.0163e-06, -4.0163e-06,  ..., -4.0163e-06,\n",
      "        -4.0163e-06, -4.0163e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #87, criterion=6.649627461573103, phi=6.656294128239684, f=-0.006666666666580773\n",
      "lambda=tensor([-4.0669e-06, -4.0669e-06, -4.0669e-06,  ..., -4.0669e-06,\n",
      "        -4.0669e-06, -4.0669e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #88, criterion=6.649526392892753, phi=6.656193059559332, f=-0.006666666666578794\n",
      "lambda=tensor([-4.1175e-06, -4.1175e-06, -4.1175e-06,  ..., -4.1175e-06,\n",
      "        -4.1175e-06, -4.1175e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #89, criterion=6.649425179866681, phi=6.656091846533258, f=-0.006666666666576783\n",
      "lambda=tensor([-4.1683e-06, -4.1683e-06, -4.1683e-06,  ..., -4.1683e-06,\n",
      "        -4.1683e-06, -4.1683e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #90, criterion=6.649323824515939, phi=6.655990491182513, f=-0.006666666666574741\n",
      "lambda=tensor([-4.2191e-06, -4.2191e-06, -4.2191e-06,  ..., -4.2191e-06,\n",
      "        -4.2191e-06, -4.2191e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #91, criterion=6.64922232698223, phi=6.655888993648802, f=-0.006666666666572664\n",
      "lambda=tensor([-4.2699e-06, -4.2699e-06, -4.2699e-06,  ..., -4.2699e-06,\n",
      "        -4.2699e-06, -4.2699e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #92, criterion=6.649120689110237, phi=6.655787355776808, f=-0.0066666666665705565\n",
      "lambda=tensor([-4.3209e-06, -4.3209e-06, -4.3209e-06,  ..., -4.3209e-06,\n",
      "        -4.3209e-06, -4.3209e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #93, criterion=6.6490189115925675, phi=6.655685578259136, f=-0.0066666666665684176\n",
      "lambda=tensor([-4.3719e-06, -4.3719e-06, -4.3719e-06,  ..., -4.3719e-06,\n",
      "        -4.3719e-06, -4.3719e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #94, criterion=6.648916995783297, phi=6.655583662449864, f=-0.006666666666566248\n",
      "lambda=tensor([-4.4230e-06, -4.4230e-06, -4.4230e-06,  ..., -4.4230e-06,\n",
      "        -4.4230e-06, -4.4230e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #95, criterion=6.648814942050321, phi=6.655481608716885, f=-0.006666666666564049\n",
      "lambda=tensor([-4.4741e-06, -4.4741e-06, -4.4741e-06,  ..., -4.4741e-06,\n",
      "        -4.4741e-06, -4.4741e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #96, criterion=6.648712751933431, phi=6.655379418599993, f=-0.006666666666561815\n",
      "lambda=tensor([-4.5253e-06, -4.5253e-06, -4.5253e-06,  ..., -4.5253e-06,\n",
      "        -4.5253e-06, -4.5253e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #97, criterion=6.648610425848107, phi=6.655277092514666, f=-0.006666666666559554\n",
      "lambda=tensor([-4.5766e-06, -4.5766e-06, -4.5766e-06,  ..., -4.5766e-06,\n",
      "        -4.5766e-06, -4.5766e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #98, criterion=6.648507965274387, phi=6.655174631940945, f=-0.006666666666557262\n",
      "lambda=tensor([-4.6279e-06, -4.6279e-06, -4.6279e-06,  ..., -4.6279e-06,\n",
      "        -4.6279e-06, -4.6279e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #99, criterion=6.648405371088354, phi=6.655072037754909, f=-0.00666666666655494\n",
      "lambda=tensor([-4.6794e-06, -4.6794e-06, -4.6794e-06,  ..., -4.6794e-06,\n",
      "        -4.6794e-06, -4.6794e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "Step #100, criterion=6.648302643831143, phi=6.6549693104976955, f=-0.006666666666552583\n",
      "lambda=tensor([-4.7308e-06, -4.7308e-06, -4.7308e-06,  ..., -4.7308e-06,\n",
      "        -4.7308e-06, -4.7308e-06], dtype=torch.float64)\n",
      "x_hat=tensor([1.2755e-03, 6.0745e-34, 2.8929e-64,  ..., 2.8929e-64, 6.0745e-34,\n",
      "        1.2755e-03], dtype=torch.float64)\n",
      "\n",
      "CPU times: user 1h 31min 36s, sys: 5min 49s, total: 1h 37min 25s\n",
      "Wall time: 25min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = run_experiment(M_p, gamma, eps, image_index, max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1758dd38-5293-4279-b3b2-6446231281e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1131e-04, 5.5362e-05, 2.7535e-05,  ..., 2.7535e-05, 5.5362e-05,\n",
       "        1.1131e-04], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = optimizer._calculate_primal_var(optimizer.param_groups[0]['params'][0]).detach().clone()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f97f8b10-e1ed-4a95-bb1f-0439c6ad1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbddf0d-5299-486f-9e46-33a6b67ece30",
   "metadata": {},
   "source": [
    "## Output test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4ecc36f-04a1-4d8d-b3e3-edf722be38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = optimizer.param_groups[0]['params'][0]\n",
    "x = optimizer._calculate_x(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c429fd4-c05e-4d38-bb98-05144a47adbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d1ca490>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((x.view(n, n) @ torch.ones(n, dtype=float)).view(int(n ** 0.5), int(n ** 0.5)).detach().clone().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9eb191-4ba9-4003-89fb-1cb93190c122",
   "metadata": {},
   "source": [
    "# Primal-Dual gradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c4bed83-2d97-4d4b-83a1-c439363c20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-3\n",
    "k = 0\n",
    "\n",
    "epsp = eps/8\n",
    "p,q = mnist(epsp, p_list[k], q_list[k])\n",
    "p_ref, q_ref = mnist(0, p_list[k], q_list[k])\n",
    "            \n",
    "n = 28 #64 #28\n",
    "a = p.copy()\n",
    "b = q.copy()\n",
    "\n",
    "temp = []\n",
    "for i in range(n ** 2):\n",
    "    temp.append([i // n, i % n])\n",
    "M = cdist(temp, temp)\n",
    "M = M * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d02a98-31f2-45e2-8ecc-ce3af6a5d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGMsDR(x_start):\n",
    "    f = phi_\n",
    "    f_primal = lambda x: f_(gamma, x)\n",
    "\n",
    "    mu = 0 #ONLY!\n",
    "    A = 0.\n",
    "    tau = 1.\n",
    "    x, v = x_start.copy(), x_start.copy()\n",
    "    primal_var = np.zeros_like(K)\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    f_x = None\n",
    "    t = np.ones(2, np.float64)\n",
    "    i = 0\n",
    "    while True:\n",
    "        y, f_y, grad_f_y, norm2_grad_f_y, x, f_x, B, t[i%2] = agmsdr_iter(i, t[i%2], f_x, x, v)\n",
    "        #print('\\n')\n",
    "        g = (f_x - f_y)\n",
    "        a = norm2_grad_f_y + 2*mu*g\n",
    "        b = 2*mu*A*g + 2*tau*g - mu*tau*(((v - y)*(v - y)).sum())\n",
    "        c = 2*A*tau*g\n",
    "\n",
    "        alpha = (-b + np.sqrt(b*b - 4*a*c)) / 2 / a\n",
    "        \n",
    "        primal_var = alpha * B + primal_var*A\n",
    "        A = A + alpha\n",
    "        \n",
    "        v = tau*v + mu*alpha*y - alpha * (grad_f_y)\n",
    "        tau = tau+mu*alpha\n",
    "        v/=tau\n",
    "        \n",
    "        primal_var/=A\n",
    "        \n",
    "        #print((C * (B_round(primal_var) - primal_var)).sum(), f_primal(primal_var) + f_x, eps/6)\n",
    "        if (C * (B_round(primal_var) - primal_var)).sum() <= eps/6 and abs(f_primal(primal_var) + f_x) <= eps/6:\n",
    "            return time.perf_counter() - start_time\n",
    "        i-=-1\n",
    "            \n",
    "    return np.array(history_f), np.array(history_time)\n",
    "\n",
    "def agmsdr_iter(i, t, f_x, x, v):\n",
    "    def check(t, forcereturn=False):\n",
    "        \n",
    "        #print(i,': ', t)\n",
    "        y = v + t * (x-v)\n",
    "        logB = (K + np.outer(y[:n], one) + np.outer(one, y[n:]))\n",
    "        max_logB = (logB).max()\n",
    "        logB_stable = logB - max_logB\n",
    "        B_stable = np.exp(logB_stable)\n",
    "        u_hat_stable, v_hat_stable = B_stable.dot(one), B_stable.T.dot(one)\n",
    "        \n",
    "        Bs_stable = u_hat_stable.sum()\n",
    "\n",
    "        f_y = gamma*(-y[:n].dot(p) - y[n:].dot(q) + np.log(Bs_stable) + max_logB)\n",
    "        grad_f_y = gamma*np.concatenate((-p + u_hat_stable/Bs_stable, -q + v_hat_stable/Bs_stable),0)\n",
    "        #B_stable/Bs_stable\n",
    "        if (grad_f_y.dot(v-y) >= 0 and f_x >= f_y) or forcereturn:\n",
    "            gu, gv = (grad_f_y[:n]**2).sum(), (grad_f_y[n:]**2).sum()\n",
    "            norm2_grad_f_y = (gu+gv)\n",
    "\n",
    "            x_new = y.copy()    \n",
    "            if gu > gv:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings('error')\n",
    "                    try:\n",
    "                        ustep = p/u_hat_stable\n",
    "                    except Warning as e:\n",
    "                        u_hat_stable/=u_hat_stable.max()\n",
    "                        u_hat_stable[u_hat_stable<1e-150] = 1e-150\n",
    "                        ustep = p/u_hat_stable\n",
    "                        #print('catchu')\n",
    "                    \n",
    "                \n",
    "                ustep/=ustep.max()\n",
    "                x_new[:n]+=np.log(ustep)\n",
    "                Z=ustep[:,None]*B_stable\n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings('error')\n",
    "                    try:\n",
    "                        vstep = q/v_hat_stable\n",
    "                    except Warning as e:\n",
    "                        v_hat_stable/=v_hat_stable.max()\n",
    "                        v_hat_stable[v_hat_stable<1e-150] = 1e-150\n",
    "                        vstep = q/v_hat_stable\n",
    "                        #print('catchv')\n",
    "\n",
    "                vstep/=vstep.max()\n",
    "                x_new[n:]+=np.log(vstep)\n",
    "                Z=B_stable*vstep[None,:]\n",
    "            f_x_new=gamma*(np.log(Z.sum())+max_logB-x_new[:n].dot(p)-x_new[n:].dot(q))\n",
    "            #print(phi_(gamma,x_new) -f_x_new)\n",
    "\n",
    "            return True, (y, f_y, grad_f_y , norm2_grad_f_y, x_new, f_x_new, B_stable/Bs_stable, t) #f(x_new) can be optimized\n",
    "        else:\n",
    "            return False, grad_f_y\n",
    "\n",
    "    if f_x==None: f_x = phi_(gamma, x) \n",
    "    tl=None\n",
    "    tr=np.float128(t)\n",
    "    k=0\n",
    "    while True: #find right endpoint for line search\n",
    "        is_ok, ret = check(tr)\n",
    "        if is_ok:\n",
    "            return ret\n",
    "        else:\n",
    "            gr = ret\n",
    "        if gr.dot(x-v) < 0:\n",
    "            tl=tr\n",
    "            tr= 1 + 1e-8 * k**10\n",
    "        else:\n",
    "            break\n",
    "        k-=-1\n",
    "\n",
    "    \n",
    "    # small step to the left    \n",
    "    tmp=max(0, min(tr-(1 - (i+1)/(i+2)), (i+1)/(i+2))) \n",
    "    while tl==None: #find left endpoint for line search\n",
    "        is_ok, ret = check(tmp)\n",
    "        if is_ok:\n",
    "            return ret\n",
    "        else:\n",
    "            gtmp = ret\n",
    "        if gtmp.dot(x-v) <= 0:\n",
    "            tl=tmp\n",
    "            break\n",
    "        else:\n",
    "            tr=tmp\n",
    "        tmp = 1 - (1-tmp**(4)) \n",
    "\n",
    "    \n",
    "    # search in [tl,tr]\n",
    "    while True:\n",
    "        if tr < 0.8 or tl >= 1.:\n",
    "            tc = tl + (tr-tl)*3/5\n",
    "        else:\n",
    "            tc = tl + (tr-tl)*4/5\n",
    "\n",
    "        is_ok, ret = check(tc, tc==tr or tc==tl)\n",
    "\n",
    "        if is_ok:\n",
    "            return ret\n",
    "        else:\n",
    "            gc = ret\n",
    "        if gc.dot(x-v) > 0:\n",
    "            tr=tc\n",
    "        else:\n",
    "            tl=tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca525b0-158c-4ad9-97df-fe2ea0fc80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for k in range(len(p_list)):\n",
    "    y_array = np.zeros_like(epslist)\n",
    "    # if not os.path.isfile('/content/drive/My Drive/colab/'+'!e_'+'agm_'+str(k)+'.npy'):\n",
    "    i = 0\n",
    "    for eps in epslist:\n",
    "        epsp = eps / 8\n",
    "        p, q = mnist(epsp, p_list[k], q_list[k])\n",
    "        p_ref, q_ref = mnist(0, p_list[k], q_list[k])\n",
    "        gamma = eps / 3 / np.log(n)\n",
    "        K = -C / gamma\n",
    "        y_array[i] = AGMsDR(x0)\n",
    "        i -= -1\n",
    "        # np.save('/content/drive/My Drive/colab/'+'!e_'+'agm_'+str(k)+'.npy', y_array)\n",
    "    print('agm_', k, ' - done', y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959bbec-3da3-46ff-a416-7c97032fc9fe",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8fe3fd23-4a34-4350-98bc-55e7d53043b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab5aa8a6-a289-4cb0-947e-6010997417c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3103ff9-bd3b-4eb8-9bb5-4e243cff1e19",
   "metadata": {
    "id": "E22l1T_LjLNW"
   },
   "outputs": [],
   "source": [
    "#experiments were done for\n",
    "p_list = [34860, 31226,   239, 37372, 17390]\n",
    "q_list = [45815, 35817, 43981, 54698, 49947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e49bf7f-7928-46fe-b0d9-52bd93b6cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-3\n",
    "k=3\n",
    "\n",
    "epsp = eps\n",
    "p,q = mnist(epsp, p_list[k], q_list[k])\n",
    "p_ref, q_ref = mnist(0, p_list[k], q_list[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b8b6f6c-f5f7-4f5e-99b2-45c1e89841b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1430e5e50>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "axes[0, 0].imshow(p_ref.reshape((28, 28)))\n",
    "axes[0, 1].imshow(p.reshape((28, 28)))\n",
    "axes[1, 0].imshow(q_ref.reshape((28, 28)))\n",
    "axes[1, 1].imshow(q.reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a318fa4-e84f-4c6c-b964-3f2b24bf3732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor_methods)",
   "language": "python",
   "name": "tensor_methods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
